{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "663490b4",
   "metadata": {},
   "source": [
    "# Apache TVM - an in-depth look\n",
    "\n",
    "This notebook will demonstrate basics of TVM expressions and schedules.\n",
    "\n",
    "Let's start with importing TVM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ce509b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tvm\n",
    "from tvm import te\n",
    "\n",
    "import difflib\n",
    "import sys\n",
    "\n",
    "\n",
    "def compute_diff(s1: str, s2: str):\n",
    "    \"\"\"\n",
    "    Demonstrates differences between two strings, line by line.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    s1: str\n",
    "        First sequence to compare\n",
    "    s2: str\n",
    "        Second sequence to compare\n",
    "    \"\"\"\n",
    "    s1split = s1.split('\\n')\n",
    "    s2split = s2.split('\\n')\n",
    "    delta = difflib.ndiff(\n",
    "        s1split,\n",
    "        s2split\n",
    "    )\n",
    "    for line in delta:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788d8a8f",
   "metadata": {},
   "source": [
    "## Defining schedules\n",
    "\n",
    "**Schedules** are set of transformations applied to computations.\n",
    "\n",
    "`tvm.te` provides Tensor Expressions used both by Relay to represent operations in the model functions, as in schedules/optimization strategies to organize operations.\n",
    "\n",
    "### Creating computation\n",
    "\n",
    "Let's perform element-wise matrix multiplication.\n",
    "\n",
    "* `te.var` define single-value variables.\n",
    "* `te.placeholder` are responsible for creating and managing space for tensors.\n",
    "* `te.compute` constructs a new tensor by computing data over the shape domain with given function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa148b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = te.var('n')\n",
    "m = te.var('m')\n",
    "\n",
    "A = te.placeholder((m, n), name='A')\n",
    "B = te.placeholder((m, n), name='B')\n",
    "C = te.compute((m, n), lambda i, j: A[i, j] * B[i, j], name='C')\n",
    "\n",
    "schedule = te.create_schedule([C.op])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beec19b7",
   "metadata": {},
   "source": [
    "### Lowering computations\n",
    "\n",
    "`tvm.lower` transforms the computation definition into real callable function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5017665",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_function = str(tvm.lower(schedule, [A, B, C], simple_mode=True))\n",
    "\n",
    "print(base_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312a917a",
   "metadata": {},
   "source": [
    "### Splitting and tiling computations\n",
    "\n",
    "https://tvm.apache.org/docs/reference/api/python/te.html#tvm.te.Stage.split\n",
    "\n",
    "`split` splits a given axis by `factor` into outer and inner axis (inner axis has `factor` length), where inner axis has a `factor` length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac40433",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = te.var('n')\n",
    "m = te.var('m')\n",
    "\n",
    "A = te.placeholder((m, n), name='A')\n",
    "B = te.placeholder((m, n), name='B')\n",
    "C = te.compute((m, n), lambda i, j: A[i, j] * B[i, j], name='C')\n",
    "\n",
    "schedule = te.create_schedule([C.op])\n",
    "\n",
    "xo, xi = schedule[C].split(C.op.axis[0], factor=32)\n",
    "\n",
    "split_function = str(tvm.lower(schedule, [A, B, C], simple_mode=True))\n",
    "\n",
    "print(split_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea38df2",
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "compute_diff(base_function, split_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4018e6c4",
   "metadata": {},
   "source": [
    "https://tvm.apache.org/docs/reference/api/python/te.html#tvm.te.Stage.tile\n",
    "\n",
    "Same as split, but in 2D - tiles the computations along given axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0b348b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = te.var('n')\n",
    "m = te.var('m')\n",
    "\n",
    "A = te.placeholder((m, n), name='A')\n",
    "B = te.placeholder((m, n), name='B')\n",
    "C = te.compute((m, n), lambda i, j: A[i, j] * B[i, j], name='C')\n",
    "\n",
    "schedule = te.create_schedule([C.op])\n",
    "\n",
    "xo, xi, yo, yi = schedule[C].tile(C.op.axis[0], C.op.axis[1], x_factor=16, y_factor=8)\n",
    "\n",
    "tile_function = str(tvm.lower(schedule, [A, B, C], simple_mode=True))\n",
    "\n",
    "print(split_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f83dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_diff(base_function, tile_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23c197c",
   "metadata": {},
   "source": [
    "### Fusing axes\n",
    "\n",
    "https://tvm.apache.org/docs/reference/api/python/te.html#tvm.te.Stage.fuse\n",
    "\n",
    "Fuses two consecutive axes into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbf6204",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = te.var('n')\n",
    "m = te.var('m')\n",
    "\n",
    "A = te.placeholder((m, n), name='A')\n",
    "B = te.placeholder((m, n), name='B')\n",
    "C = te.compute((m, n), lambda i, j: A[i, j] * B[i, j], name='C')\n",
    "\n",
    "schedule = te.create_schedule([C.op])\n",
    "\n",
    "fusedaxis = schedule[C].fuse(C.op.axis[0], C.op.axis[1])\n",
    "\n",
    "fuse_function = str(tvm.lower(schedule, [A, B, C], simple_mode=True))\n",
    "\n",
    "print(fuse_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce56379",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_diff(base_function, fuse_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91acf571",
   "metadata": {},
   "source": [
    "### Binding thread axis\n",
    "\n",
    "Threading is a common concept in GEMM and linear algebra computations. It is possible to bind a specified axis to threads, e.g. CUDA thread blocks and threads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3c67ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = te.var('n')\n",
    "m = te.var('m')\n",
    "\n",
    "A = te.placeholder((m, n), name='A')\n",
    "B = te.placeholder((m, n), name='B')\n",
    "C = te.compute((m, n), lambda i, j: A[i, j] * B[i, j], name='C')\n",
    "\n",
    "schedule = te.create_schedule([C.op])\n",
    "\n",
    "co, ci = schedule[C].split(C.op.axis[0], factor=64)\n",
    "\n",
    "schedule[C].bind(co, te.thread_axis('blockIdx.x'))\n",
    "schedule[C].bind(ci, te.thread_axis('threadIdx.x'))\n",
    "\n",
    "bind_function = str(tvm.lower(schedule, [A, B, C], simple_mode=True))\n",
    "\n",
    "print(bind_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86fa267",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_diff(base_function, bind_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713c9f63",
   "metadata": {},
   "source": [
    "### Reordering computation of axes\n",
    "\n",
    "https://tvm.apache.org/docs/reference/api/python/te.html#tvm.te.Stage.reorder\n",
    "\n",
    "Reorders computation of axes - let's test it on tiled example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b213cbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = te.var('n')\n",
    "m = te.var('m')\n",
    "\n",
    "A = te.placeholder((m, n), name='A')\n",
    "B = te.placeholder((m, n), name='B')\n",
    "C = te.compute((m, n), lambda i, j: A[i, j] * B[i, j], name='C')\n",
    "\n",
    "schedule = te.create_schedule([C.op])\n",
    "\n",
    "xo, xi, yo, yi = schedule[C].tile(C.op.axis[0], C.op.axis[1], x_factor=16, y_factor=8)\n",
    "\n",
    "schedule[C].reorder(xo, yo, xi, yi)\n",
    "\n",
    "reordered_function = str(tvm.lower(schedule, [A, B, C], simple_mode=True))\n",
    "\n",
    "print(reordered_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e7f114",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_diff(tile_function, reordered_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a556ebe7",
   "metadata": {},
   "source": [
    "### Shifting computations\n",
    "\n",
    "Let's define a schedule with multiple operations in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42283503",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = te.var('m')\n",
    "\n",
    "A = te.placeholder((m,), name=\"A\")\n",
    "B = te.compute((m,), lambda i: A[i] + 1, name=\"B\")\n",
    "C = te.compute((m,), lambda i: B[i] * 2, name=\"C\")\n",
    "\n",
    "schedule = te.create_schedule(C.op)\n",
    "base_op_chain = str(tvm.lower(schedule, [A, B, C], simple_mode=True))\n",
    "print(base_op_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f94fabf",
   "metadata": {},
   "source": [
    "Each computation is handled separately.\n",
    "However, it is possible to move computations so they can share the same loop.\n",
    "For this, we can use `compute_at`.\n",
    "\n",
    "https://tvm.apache.org/docs/reference/api/python/te.html#tvm.te.Stage.compute_at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba8567f",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = te.var('m')\n",
    "\n",
    "A = te.placeholder((m,), name=\"A\")\n",
    "B = te.compute((m,), lambda i: A[i] + 1, name=\"B\")\n",
    "C = te.compute((m,), lambda i: B[i] * 2, name=\"C\")\n",
    "\n",
    "schedule = te.create_schedule(C.op)\n",
    "\n",
    "schedule[B].compute_at(schedule[C], C.op.axis[0])\n",
    "\n",
    "computeshift_op_chain = str(tvm.lower(schedule, [A, B, C], simple_mode=True))\n",
    "print(computeshift_op_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3f78cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_diff(base_op_chain, computeshift_op_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a722679",
   "metadata": {},
   "source": [
    "## Axis reduction\n",
    "\n",
    "In neural network models, one of the most popular scenarios is reduction along given axis using such functions as +, -, *\n",
    "\n",
    "In TVM, axis along which reduction occurs are created using `tvm.te.reduce_axis` constructors and stored in `tvm.te.Tensor.op.reduce_axis` (regular axes are stored in `tvm.te.Tensor.op.axis`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173fa420",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = te.var(\"n\")\n",
    "m = te.var(\"m\")\n",
    "\n",
    "A = te.placeholder((n, m), name=\"A\")\n",
    "\n",
    "k = te.reduce_axis((0, m), \"k\")\n",
    "\n",
    "B = te.compute((n,), lambda i: te.sum(A[i, k], axis=k), name=\"B\")\n",
    "\n",
    "schedule = te.create_schedule(B.op)\n",
    "reduced_axis = str(tvm.lower(schedule, [A, B], simple_mode=True))\n",
    "\n",
    "print(reduced_axis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ecc55b",
   "metadata": {},
   "source": [
    "It is also possible to perform `split` and `bind` on reduce axis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6d07b1",
   "metadata": {},
   "source": [
    "## Lowering of operations in TVM\n",
    "\n",
    "`tvm.te` module provides all kinds of typical functions occuring in linear algebra and neural networks.\n",
    "\n",
    "See [`tvm.te` documentation](https://tvm.apache.org/docs/reference/api/python/te.html) for more details.\n",
    "\n",
    "When building the model, those functions (so called **Unified intrinsic calls**) are replaced with target-specific functions and/or implementations.\n",
    "\n",
    "### Sample implementation of operation\n",
    "\n",
    "Let's create a schedule computing sigmoid function and check it's OpenCL implementation.\n",
    "\n",
    "*Note: `blockIdx.x` and `threadIdx.x` are used in OpenCL to represent GPU workgroups and their individual threads - they are accessed via `get_group_id` and `get_local_id`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d539b840",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = te.var(\"n\")\n",
    "A = te.placeholder((n,), name=\"A\")\n",
    "B = te.compute(A.shape, lambda i: te.sigmoid(A[i]), name=\"B\")\n",
    "schedule = te.create_schedule(B.op)\n",
    "num_thread = 64\n",
    "bx, tx = schedule[B].split(B.op.axis[0], factor=num_thread)\n",
    "schedule[B].bind(bx, te.thread_axis(\"blockIdx.x\"))\n",
    "schedule[B].bind(tx, te.thread_axis(\"threadIdx.x\"))\n",
    "\n",
    "print(tvm.lower(schedule, [A, B], simple_mode=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae33fc3b",
   "metadata": {},
   "source": [
    "As it can be observed, sigmoid is represented here as tir function `tir.sigmoid` - let's see how it is implemented in OpenCL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7dd63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fopencl = tvm.build(schedule, [A, B], \"opencl\", name=\"mysigm\")\n",
    "print(fopencl.imported_modules[0].get_source())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b97bc1",
   "metadata": {},
   "source": [
    "### Creating custom implementation of the operation\n",
    "\n",
    "Adding new operation/function from the Python level is relatively easy, as long as necessary computation blocks are provided (lower-level implementations of kernels need to be handled in C++).\n",
    "\n",
    "For a new operation/function, we need to create and register it and provide a lowering rule converting the operation to its implementation in supported targets.\n",
    "\n",
    "*Note: demonstrated lowering of rules can be also used for existing operations to use our custom implementation of a certain function - its selection can be controlled with `level` parameter determining priority*\n",
    "\n",
    "Let's add our custom `log` implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c12a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mylog(x):\n",
    "    \"\"\"customized log intrinsic function\"\"\"\n",
    "    return tvm.tir.call_intrin(x.dtype, \"tir.mylog\", x)\n",
    "\n",
    "\n",
    "def opencl_mylog_rule(op):\n",
    "    \"\"\"OpenCL lowering rule for log\"\"\"\n",
    "    if op.dtype == \"float32\":\n",
    "        return tvm.tir.call_pure_extern(\"float32\", \"log\", op.args[0])\n",
    "    else:\n",
    "        return op\n",
    "\n",
    "\n",
    "tvm.ir.register_op_attr(\"tir.mylog\", \"TCallEffectKind\", tvm.tir.CallEffectKind.Pure)\n",
    "tvm.ir.register_intrin_lowering(\"tir.mylog\", target=\"opencl\", f=opencl_mylog_rule, level=99)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894ccf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = te.var(\"n\")\n",
    "A = te.placeholder((n,), name=\"A\")\n",
    "B = te.compute(A.shape, lambda i: mylog(A[i]), name=\"B\")\n",
    "schedule = te.create_schedule(B.op)\n",
    "num_thread = 64\n",
    "bx, tx = schedule[B].split(B.op.axis[0], factor=num_thread)\n",
    "schedule[B].bind(bx, te.thread_axis(\"blockIdx.x\"))\n",
    "schedule[B].bind(tx, te.thread_axis(\"threadIdx.x\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee98094",
   "metadata": {},
   "outputs": [],
   "source": [
    "fopencl = tvm.build(schedule, [A, B], \"opencl\", name=\"mykernel\")\n",
    "print(fopencl.imported_modules[0].get_source())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2567ed",
   "metadata": {},
   "source": [
    "## Analyzing model's code\n",
    "\n",
    "For building whole models from frontends, we use `relay.build`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18da8a5b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import onnx\n",
    "import tvm.relay as relay\n",
    "\n",
    "onnxmodel = onnx.load('../models/test-delegate-one-input.onnx')\n",
    "mod, params = relay.frontend.from_onnx(\n",
    "    onnxmodel,\n",
    "    freeze_params=True,\n",
    "    dtype='float32'\n",
    ")\n",
    "\n",
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    graph, lib, params = relay.build(\n",
    "        mod['main'],\n",
    "        target='c'\n",
    "    )\n",
    "    \n",
    "    print(lib.get_source())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95c968e",
   "metadata": {},
   "source": [
    "## Model compilation, evaluation and fine-tuning\n",
    "\n",
    "The above aspects of TVM are covered in homework tasks.\n",
    "\n",
    "## References\n",
    "\n",
    "* [Schedule primitives in TVM](https://tvm.apache.org/docs/how_to/work_with_schedules/schedule_primitives.html#sphx-glr-how-to-work-with-schedules-schedule-primitives-py)\n",
    "* [Reduction in TVM](https://tvm.apache.org/docs/how_to/work_with_schedules/reduction.html#sphx-glr-how-to-work-with-schedules-reduction-py)\n",
    "* [TVM intrinsics and math functions](https://tvm.apache.org/docs/how_to/work_with_schedules/intrin_math.html#sphx-glr-how-to-work-with-schedules-intrin-math-py)\n",
    "\n",
    "## Useful additional resources\n",
    "\n",
    "* [TVM User how-to guides](https://tvm.apache.org/docs/how_to/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fa312a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
